{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pipeline import vector_comparison\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import vector_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/training.csv', index_col = 0)\n",
    "#df = df.iloc[:1000] #need to limit rows while running on local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "model = vector_comparison(df)\n",
    "X_train, X_test = model.split_data(['question1','question2'], 'is_duplicate') # ran to get self.fitting_text\n",
    "\n",
    "y_train = model.y_train\n",
    "\n",
    "token.fit_on_texts(model.fitting_text)\n",
    "seq1 = token.texts_to_sequences(X_train['question1'].values)\n",
    "seq2 = token.texts_to_sequences(X_train['question2'].values)\n",
    "\n",
    "\n",
    "#vsalidation data\n",
    "\n",
    "y_val = model.y_test\n",
    "\n",
    "token.fit_on_texts(model.fitting_text)\n",
    "seq1_val = token.texts_to_sequences(X_test['question1'].values)\n",
    "seq2_val = token.texts_to_sequences(X_test['question2'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(token.index_word) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#average querstion lenght to set max_len\n",
    "def seq_dist(seq1, seq2):\n",
    "    temp1, temp2 = [], []\n",
    "    for i in seq1:\n",
    "        temp1.append(len(i))\n",
    "    for i in seq2:\n",
    "        temp2.append(len(i))\n",
    "    sns.distplot(temp1)\n",
    "    sns.distplot(temp2)\n",
    "    return np.mean(temp1), np.mean(temp1)\n",
    "\n",
    "seq_dist(seq1, seq2)\n",
    "\n",
    "max_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "seq1_pad = pad_sequences(seq1, maxlen = max_len, padding ='pre')\n",
    "seq2_pad = pad_sequences(seq2, maxlen = max_len, padding ='pre')\n",
    "\n",
    "seq1_pad_val =pad_sequences(seq1_val, maxlen = max_len, padding ='pre')\n",
    "seq2_pad_val =pad_sequences(seq2_val, maxlen = max_len, padding ='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(seq1_pad.shape[1],))\n",
    "input_2 = Input(shape=(seq2_pad.shape[1],))\n",
    "\n",
    "\n",
    "from keras.layers import Input, LSTM, Flatten, Dense, Concatenate, Multiply, Dropout, Subtract, Add, Embedding, Activation\n",
    "from keras.layers.core import Lambda \n",
    "\n",
    "from sklearn.metrics import roc_auc_score as auroc\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('src/glove.6B/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embeded_dim = len(embeddings_index['the'])\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, embeded_dim))\n",
    "for word, i in token.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_lstm_1 = LSTM(100,return_sequences=True, activation=\"tanh\")\n",
    "common_lstm_2 = LSTM(100,return_sequences=True, activation=\"tanh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_1 = e(input_1)\n",
    "lstm_2 = e(input_2)\n",
    "\n",
    "#seq1 path\n",
    "vector_1 = common_lstm_1(lstm_1)\n",
    "vector_1 = common_lstm_2(vector_1)\n",
    "vector_1 = Flatten()(vector_1)\n",
    "\n",
    "#seq2 path\n",
    "vector_2 = common_lstm_1(lstm_2)\n",
    "vector_2 = common_lstm_2(vector_2)\n",
    "vector_2 = Flatten()(vector_2)\n",
    "\n",
    "cosine_sim = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([vector_1, vector_2])\n",
    "\n",
    "x = Dense(100, activation=\"tanh\", name='conc_layer')(cosine_sim)\n",
    "x = Dropout(0.01)(x)\n",
    "out = Dense(1, activation=\"sigmoid\", name = 'out')(x)\n",
    "\n",
    "model = Model([input_1, input_2], cosine_sim)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 300)      22570200    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 30, 100)      160400      embedding_1[6][0]                \n",
      "                                                                 embedding_1[7][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 30, 100)      80400       lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 3000)         0           lstm_2[6][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 3000)         0           lstm_2[7][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,811,000\n",
      "Trainable params: 240,800\n",
      "Non-trainable params: 22,570,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242608 samples, validate on 80870 samples\n",
      "Epoch 1/5\n",
      " 35000/242608 [===>..........................] - ETA: 3:25 - loss: 5.6030 - acc: 0.6292"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-999b8cb742fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit([seq1_pad,seq2_pad],y_train.values.reshape(-1,1), epochs = 5, batch_size = 5000,\n\u001b[0;32m----> 2\u001b[0;31m           validation_data=([seq1_pad_val,seq2_pad_val],y_val.values.reshape(-1,1)))\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([seq1_pad,seq2_pad],y_train.values.reshape(-1,1), epochs = 5, batch_size = 5000,\n",
    "          validation_data=([seq1_pad_val,seq2_pad_val],y_val.values.reshape(-1,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6303419508012926"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - y_train.sum()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75234"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75234, 300)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['the'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
